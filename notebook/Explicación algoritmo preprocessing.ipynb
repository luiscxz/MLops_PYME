{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "435d9498",
   "metadata": {},
   "source": [
    "En este cuaderno se explica el funcionamiento de la clase `CovaltoCsvDataCleane`. Esta clase tiene como propósito limpiar los datos provenientes de un archivo CSV.\n",
    "\n",
    "Está compuesta por los siguientes métodos:\n",
    "\n",
    "- __init__: inicializa la clase con la ruta del archivo y verifica que dicho archivo exista. En caso contrario, lanza un error indicando que el archivo no fue encontrado.\n",
    "\n",
    "- **load_dataset**: Lee el archivo CSV indicado en la ruta de la clase, lo convierte en un DataFrame de pandas y lo retorna para su posterior procesamiento.\n",
    "\n",
    "- **remove_outliers**: Elimina los valores atípicos usando Medcopule. El **medcouple** es una medida robusta de **asimetría** basada en los valores centrales de la distribución.\n",
    "    - Si **MC > 0**, la distribución tiene **asimetría positiva** (cola larga a la derecha).\n",
    "    - Si **MC < 0**, la distribución tiene **asimetría negativa** (cola larga a la izquierda).\n",
    "    - Si **MC ≈ 0**, la distribución es aproximadamente **simétrica**.\n",
    "\n",
    "    A diferencia de la **asimetría de Pearson**, el medcouple es **más robusto**, ya que no depende de la media y la varianza, sino de la **mediana** y la **dispersión relativa de los datos**.\n",
    "\n",
    "    Se calcula de la siguiente manera: si los datos son $x_1,x_2,..,x_n$ y $Me$ es la mediana, para cada par de datos $x_i,x_j$ que cumplan $x_i\\le Me\\le x_j$ y $x_i\\neq x_j$ se define $$h(x_i,x_j)=\\frac{(x_j-Me)-(Me-x_i)}{x_j-x_i}$$ y la Medcouple se calcula como $ MC= $ mediana de todos los $h(x_i,x_j)$. Se trata de un estimador robusto de la simetría.\n",
    "\n",
    "\n",
    "- standardize_sector_column: Se encarga de reemplazar la frase `retail` por `Retail` en la columna `sector_industrial`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcdfd223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from statsmodels.stats.stattools import medcouple\n",
    "# Busca hacia arriba hasta encontrar la carpeta 'data'\n",
    "project_root = next(p for p in Path.cwd().parents if (p / 'data').exists()) \n",
    "file_path = lambda file : os.path.join(project_root,'data/raw',file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77df16b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Autor: Luis A. García\n",
    "Email: luisgarcia.oq95@gmail.com\n",
    "Creado: 22 de octubre del 2025\n",
    "\n",
    "Este código está diseñado para limpiar los datos del proyecto \n",
    "MLOPS_PYME, su función principal es:\n",
    "    • Limpiar valores atípicos\n",
    "    • Estandarizar la varibale categória \"Retail\"\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.stattools import medcouple\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "class CovaltoCsvDataCleaner:\n",
    "    \"\"\"\n",
    "    Clase encargada de limpiar los datos provenientes de un archivo csv de la \n",
    "    base de datos de covalto.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    file_path: str or Path\n",
    "        Ruta del archivo csv a limpiar\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,file_path):\n",
    "\n",
    "        \"\"\"\n",
    "        función que inicializa la clase con la ruta del archivo y verifica que\n",
    "        el archivo exista.\n",
    "        \n",
    "        Attributes\n",
    "        ----------\n",
    "        file_path: Ruta del archivo csv a limpiar\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        FileNotFoundError\n",
    "            Si el archivo específicado no existe\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.file_path = Path(file_path)\n",
    "        if not self.file_path.exists():\n",
    "            raise FileNotFoundError(f\"El archivo no existe: {self.file_path}\")\n",
    "        \n",
    "        self.data = None                    \n",
    "        \n",
    "\n",
    "    \n",
    "    def load_dataset(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Lee el archivo csv indicado en el self.file_path y lo carga como un\n",
    "        dataframe de pandas.\n",
    "\n",
    "        return\n",
    "        ------\n",
    "        pd.DataFrame\n",
    "            DataFrame que contiene los datos leidos del archivo csv.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        pandas.errors.EmptyDataError\n",
    "            Si el archivo está vacío\n",
    "\n",
    "        pandas.errors.ParserError\n",
    "            Si el archivo CSV tiene errores de formato o no puede ser parseado correctamente.\n",
    "        \"\"\"\n",
    "\n",
    "        self.data = pd.read_csv(self.file_path)\n",
    "        return self.data\n",
    "    \n",
    "    \n",
    "    def remove_outliers(self, col_interes='ingresos_anuales_mxn',max_retries=3):\n",
    "\n",
    "        \"\"\"\n",
    "        Elimina los valores atípicos de una columna numérica usando el estadístico MedCouple (MC).\n",
    "\n",
    "        Este método ajusta los límites inferior y superior de detección de outliers \n",
    "        en función de la asimetría de la distribución, medida con el estadístico MedCouple.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        covalto_dataset_raw: pd.DataFrame\n",
    "            DataFrame que contiene los datos a procesar.\n",
    "\n",
    "        col_interes: str \n",
    "            Nombre de la columna sobre la cual se eliminaran los valores atípicos.\n",
    "            Por defecto es 'ingresos_anuales_mxn'.\n",
    "\n",
    "        max_retries : int\n",
    "            Número máximo de intentos para ingresar una columna válida.\n",
    "            Por defecto es 3.\n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        pandas.DataFrame\n",
    "            Copia del DataFrame original sin los valores atípicos en la columna indicada.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            Si no se proporciona una columna válida después de varios intentos.\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "            - Si el MedCouple (MC) es positivo, se ajusta más el límite inferior.\n",
    "            - Si el MC es negativo, se ajusta más el límite superior.\n",
    "            - Si el MC es 0, se aplica la regla estándar del rango intercuartílico (IQR).\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"El dataset no ha sido cargado. Ejecute load_dataset() primero.\")\n",
    "        \n",
    "        attempt = 0\n",
    "        while attempt<max_retries:\n",
    "            try:\n",
    "                # Intenta acceder a la columna\n",
    "                data = self.data.copy()\n",
    "                _=data[col_interes]\n",
    "\n",
    "                # Calcular estadísticas\n",
    "                resumen = data[col_interes].describe()\n",
    "                Q1, Q2, Q3 = resumen.iloc[4], resumen.iloc[5], resumen.iloc[6]\n",
    "                RI = Q3 - Q1\n",
    "                MC = medcouple(data[col_interes].to_numpy())\n",
    "\n",
    "                # Determinar límites\n",
    "                if MC > 0:\n",
    "                    lim_inf_MC = Q1 - 1.5 * np.exp(-3.5 * MC) * RI\n",
    "                    lim_sup_MC = Q3 + 1.5 * np.exp(4 * MC) * RI\n",
    "                elif MC < 0:\n",
    "                    lim_inf_MC = Q1 - 1.5 * np.exp(-4 * MC) * RI\n",
    "                    lim_sup_MC = Q3 + 1.5 * np.exp(3.5 * MC) * RI\n",
    "                else:\n",
    "                    lim_inf_MC = Q1 - 1.5 * RI\n",
    "                    lim_sup_MC = Q3 + 1.5 * RI\n",
    "\n",
    "                data = data[\n",
    "                    (data[col_interes] >= lim_inf_MC) &\n",
    "                    (data[col_interes] <= lim_sup_MC) |\n",
    "                    (data[col_interes].isna())\n",
    "                ]\n",
    "                self.data = data.copy()\n",
    "                return self.data\n",
    "            \n",
    "            except KeyError:\n",
    "                print(f\"La columna '{col_interes}' no existe en el DataFrame.\")\n",
    "                attempt += 1\n",
    "                if attempt < max_retries:\n",
    "                    col_interes = input(\"Por favor, ingrese el nombre correcto de la columna: \")\n",
    "                else:\n",
    "                    raise ValueError(\"No se proporcionó una columna válida después de varios intentos.\")\n",
    "\n",
    "    def standardize_sector_column(self,col_name='sector_industrial',max_retries=3):\n",
    "        \"\"\"\n",
    "        Estandariza los nombres del sector industrial en el DataFrame.\n",
    "        \n",
    "        Reemplaza valores inconsistentes o en minúsculas por versiones normalizadas.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pandas.DataFrame\n",
    "            DataFrame a procesar.\n",
    "        \n",
    "        col_name: str\n",
    "            Nobre de la columna sobre la cual se estarizarán las categorías\n",
    "        \n",
    "        max_retries: int\n",
    "            Número máximo de intentos para ingregar una columna válida\n",
    "            Por defecto es 3.\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.DataFrame\n",
    "            Copia del DataFrame con los nombres del sector estandarizados.\n",
    "        \"\"\"\n",
    "        \n",
    "        attempt = 0\n",
    "        while attempt<max_retries:\n",
    "            try:\n",
    "                self.data[col_name] = self.data[col_name].replace({\n",
    "                 'retail': 'Retail'   \n",
    "                })\n",
    "                return self.data\n",
    "            except KeyError:\n",
    "                print(f\"la columna {col_name} no existe en el DataFrame.\")\n",
    "                attempt +=1\n",
    "                if attempt<max_retries:\n",
    "                    col_name = input('Ingrese el nombre correcto de la columna: ')\n",
    "                else:\n",
    "                    ValueError(\"No se proporcionó una columna válida después de varios intentos\")\n",
    "\n",
    "\n",
    "# Código en acción\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Obteniene la ruta general donde están los datos\n",
    "    project_root = next(p for p in Path.cwd().parents if (p / 'data').exists()) \n",
    "    file_path = lambda file : os.path.join(project_root,'data/raw',file)\n",
    "\n",
    "    # 2. Carga los datos\n",
    "    cleaner = CovaltoCsvDataCleaner(file_path('covalto_sme_credit_data.csv'))   # Crear instancia\n",
    "    data = cleaner.load_dataset()    \n",
    "\n",
    "    # 3. Limpia Outliers\n",
    "    data = cleaner.remove_outliers(\n",
    "        col_interes ='ingresos_anuales_mxn',\n",
    "        max_retries=3\n",
    "    )\n",
    "\n",
    "    # 4. Reemplaza retail por Retail en la columna 'sector_industrial'\n",
    "    data = cleaner.standardize_sector_column(\n",
    "        col_name = 'sector_industrial',\n",
    "        max_retries = 3)\n",
    "\n",
    "    # 5. Guarda el archivo preprocesado\n",
    "\n",
    "    dir_save_data = project_root/'data/processed'\n",
    "    data.to_csv(dir_save_data/ 'covalto_sme_credit_data_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
