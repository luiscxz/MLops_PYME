{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "435d9498",
   "metadata": {},
   "source": [
    "En este cuaderno se explica el funcionamiento de la clase `CovaltoCsvDataCleane`. Esta clase tiene como propósito limpiar los datos provenientes de un archivo CSV.\n",
    "\n",
    "Está compuesta por los siguientes métodos:\n",
    "\n",
    "- __init__: inicializa la clase con la ruta del archivo y verifica que dicho archivo exista. En caso contrario, lanza un error indicando que el archivo no fue encontrado.\n",
    "\n",
    "- **load_dataset**: Lee el archivo CSV indicado en la ruta de la clase, lo convierte en un DataFrame de pandas y lo retorna para su posterior procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdfd223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from statsmodels.stats.stattools import medcouple\n",
    "\n",
    "file_path = lambda file: os.path.join(os.getcwd(),'data/raw',file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77df16b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CovaltoCsvDataCleane:\n",
    "\n",
    "    \"\"\"\n",
    "    Clase encargada de limpiar los datos provenientes de un archivo csv de la \n",
    "    base de datos de covalto.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    file_path: str or Path\n",
    "        Ruta del archivo csv a limpiar\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,file_path):\n",
    "\n",
    "        \"\"\"\n",
    "        función que inicializa la clase con la ruta del archivo y verifica que\n",
    "        el archivo exista.\n",
    "        \n",
    "        Attributes\n",
    "        ----------\n",
    "        file_path: Ruta del archivo csv a limpiar\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        FileNotFoundError\n",
    "            Si el archivo específicado no existe\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.file_path = Path(file_path)\n",
    "        if not self.file_path.exists():\n",
    "            raise FileNotFoundError(f\"El archivo no existe: {self.file_path}\")\n",
    "        \n",
    "        self.data = None                    \n",
    "        \n",
    "\n",
    "    \n",
    "    def load_dataset(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Lee el archivo csv indicado en el self.file_path y lo carga como un\n",
    "        dataframe de pandas.\n",
    "\n",
    "        return\n",
    "        ------\n",
    "        pd.DataFrame\n",
    "            DataFrame que contiene los datos leidos del archivo csv.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        pandas.errors.EmptyDataError\n",
    "            Si el archivo está vacío\n",
    "\n",
    "        pandas.errors.ParserError\n",
    "            Si el archivo CSV tiene errores de formato o no puede ser parseado correctamente.\n",
    "        \"\"\"\n",
    "\n",
    "        self.data = pd.read_csv(self.file_path)\n",
    "        return self.data\n",
    "    \n",
    "    \n",
    "    def remove_outliers_medcouple(self, col_interes='ingresos_anuales_mxn',max_retries=3):\n",
    "\n",
    "        \"\"\"\n",
    "        Elimina los valores atípicos de una columna numérica usando el estadístico MedCouple (MC).\n",
    "\n",
    "        Este método ajusta los límites inferior y superior de detección de outliers \n",
    "        en función de la asimetría de la distribución, medida con el estadístico MedCouple.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        covalto_dataset_raw: pd.DataFrame\n",
    "            DataFrame que contiene los datos a procesar.\n",
    "\n",
    "        col_interes: str \n",
    "            Nombre de la columna sobre la cual se eliminaran los valores atípicos.\n",
    "            Por defecto es 'ingresos_anuales_mxn'.\n",
    "\n",
    "        max_retries : int\n",
    "            Número máximo de intentos para ingresar una columna válida.\n",
    "            Por defecto es 3.\n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        pandas.DataFrame\n",
    "            Copia del DataFrame original sin los valores atípicos en la columna indicada.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            Si no se proporciona una columna válida después de varios intentos.\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "            - Si el MedCouple (MC) es positivo, se ajusta más el límite inferior.\n",
    "            - Si el MC es negativo, se ajusta más el límite superior.\n",
    "            - Si el MC es 0, se aplica la regla estándar del rango intercuartílico (IQR).\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"El dataset no ha sido cargado. Ejecute load_dataset() primero.\")\n",
    "        \n",
    "        attempt = 0\n",
    "        while attempt<max_retries:\n",
    "            try:\n",
    "                # Intenta acceder a la columna\n",
    "                data = self.data.copy()\n",
    "                _=data[col_interes]\n",
    "\n",
    "                # Calcular estadísticas\n",
    "                resumen = data[col_interes].describe()\n",
    "                Q1, Q2, Q3 = resumen.iloc[4], resumen.iloc[5], resumen.iloc[6]\n",
    "                RI = Q3 - Q1\n",
    "                MC = medcouple(data[col_interes].to_numpy())\n",
    "\n",
    "                # Determinar límites\n",
    "                if MC > 0:\n",
    "                    lim_inf_MC = Q1 - 1.5 * np.exp(-3.5 * MC) * RI\n",
    "                    lim_sup_MC = Q3 + 1.5 * np.exp(4 * MC) * RI\n",
    "                elif MC < 0:\n",
    "                    lim_inf_MC = Q1 - 1.5 * np.exp(-4 * MC) * RI\n",
    "                    lim_sup_MC = Q3 + 1.5 * np.exp(3.5 * MC) * RI\n",
    "                else:\n",
    "                    lim_inf_MC = Q1 - 1.5 * RI\n",
    "                    lim_sup_MC = Q3 + 1.5 * RI\n",
    "\n",
    "                data = data[\n",
    "                    (data[col_interes] >= lim_inf_MC) &\n",
    "                    (data[col_interes] <= lim_sup_MC) |\n",
    "                    (data[col_interes].isna())\n",
    "                ]\n",
    "                self.data = data.copy()\n",
    "                return self.data\n",
    "            \n",
    "            except KeyError:\n",
    "                print(f\"La columna '{col_interes}' no existe en el DataFrame.\")\n",
    "                attempt += 1\n",
    "                if attempt < max_retries:\n",
    "                    col_interes = input(\"Por favor, ingrese el nombre correcto de la columna: \")\n",
    "                else:\n",
    "                    raise ValueError(\"No se proporcionó una columna válida después de varios intentos.\")\n",
    "\n",
    "    def standardize_sector_column(self,col_name='sector_industrial',max_retries=3):\n",
    "        \"\"\"\n",
    "        Estandariza los nombres del sector industrial en el DataFrame.\n",
    "        \n",
    "        Reemplaza valores inconsistentes o en minúsculas por versiones normalizadas.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pandas.DataFrame\n",
    "            DataFrame a procesar.\n",
    "        \n",
    "        col_name: str\n",
    "            Nobre de la columna sobre la cual se estarizarán las categorías\n",
    "        \n",
    "        max_retries: int\n",
    "            Número máximo de intentos para ingregar una columna válida\n",
    "            Por defecto es 3.\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.DataFrame\n",
    "            Copia del DataFrame con los nombres del sector estandarizados.\n",
    "        \"\"\"\n",
    "        \n",
    "        if col_name not in self.data.columns:\n",
    "            raise ValueError(f\"La columna {col_name} no existe en el dataset proporcionado.\")\n",
    "        \n",
    "        attempt = 0\n",
    "        while attempt<max_retries:\n",
    "            try:\n",
    "                self.data[col_name] = self.data[col_name].replace({\n",
    "                 'retail': 'Retail'   \n",
    "                })\n",
    "                return self.data\n",
    "            except KeyError:\n",
    "                print(f\"la columna {col_name} no existe en el DataFrame.\")\n",
    "                attempt +=1\n",
    "                if attempt<max_retries:\n",
    "                    col_name = print('Ingrese el nombre correcto de la columna:')\n",
    "                else:\n",
    "                    ValueError(\"No se proporcionó una columna válida después de varios intentos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3345195",
   "metadata": {},
   "source": [
    "Leamos el dataframe usando la clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6fc9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = CovaltoCsvDataCleane(file_path('covalto_sme_credit_data.csv'))   # Crear instancia\n",
    "dataset_raw = cleaner.load_dataset()        # Llamar al método\n",
    "dataset_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd771eb3",
   "metadata": {},
   "source": [
    "Limpiemos los valores atípicos usando el método remove_outliers_medcople de la clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e33de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar outliers\n",
    "dataset_clean_outliers = cleaner.remove_outliers_medcouple(\n",
    "    col_interes='ingresos_anuales_mxn',\n",
    "    max_retries=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd7200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean_outliers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9bd06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean_outliers= cleaner.standardize_sector_column()\n",
    "dataset_clean_outliers.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
