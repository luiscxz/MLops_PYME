{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "854d1934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "project_root = next(p for p in Path.cwd().parents if (p / 'data').exists())\n",
    "file_path = lambda file : os.path.join(project_root,'data/processed',file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc96734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Autor: Luis A. García\n",
    "Email: luisgarcia.oq95@gmail.com\n",
    "Creado: 22 de octubre del 2025\n",
    "\n",
    "Este código está diseñado para preparar los datos en entrenamiento y prueba del proyecto \n",
    "MLOPS_PYME, sus funciones principales son:\n",
    "    • Cargar el dataset preprocesado \n",
    "    • Feature engginering\n",
    "    • Seleccionar las variables que consideramos importantes\n",
    "    • Codificar variables ordinales\n",
    "    • Balancear clases sacando una muestra representativa\n",
    "    • Dividir los datos en entrenamiento y prueba\n",
    "\"\"\"\n",
    "\n",
    "class MlDataPreprocessor:\n",
    "    \"\"\"\n",
    "    Clase encargada de preparar y dividir los datos en entranimiento y test. \n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    file_path: str or Path\n",
    "        Ruta del archivo csv a limpiar\n",
    "    \"\"\"\n",
    "    def __init__(self,file_path):\n",
    "        \"\"\"\n",
    "        Función que inicializa la clase con la ruta del archivo y verifica que\n",
    "        el archivo exista.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        file_path: str\n",
    "            Ruta del archivo csv.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        FileNotFoundError\n",
    "            Si el archivo no existe\n",
    "\n",
    "        \"\"\"\n",
    "        self.file_path = Path(file_path)\n",
    "        if not self.file_path.exists():\n",
    "            raise FileNotFoundError(f\"No existe la ruta: {self.file_path}\")\n",
    "        self.data = None\n",
    "        self.data_train = None\n",
    "        self.data_test = None\n",
    "\n",
    "    def load_dataset(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Lee el archivo csv indicado en el self.file_path y lo carga como un\n",
    "        dataframe de pandas.\n",
    "\n",
    "        return\n",
    "        ------\n",
    "        pd.DataFrame\n",
    "            DataFrame que contiene los datos leidos del archivo csv.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        pandas.errors.EmptyDataError\n",
    "            Si el archivo está vacío\n",
    "\n",
    "        pandas.errors.ParserError\n",
    "            Si el archivo CSV tiene errores de formato o no puede ser parseado correctamente.\n",
    "        \"\"\"\n",
    "\n",
    "        self.data = pd.read_csv(self.file_path)\n",
    "        return self.data\n",
    "    \n",
    "    def create_features(self):\n",
    "        \"\"\"\n",
    "        Crea las variables más imporantes que deben ser agregadas al dataset\n",
    "\n",
    "        Raise\n",
    "        -----\n",
    "        ValueError\n",
    "            Si el dataset no ha sido cargado\n",
    "        Return\n",
    "        ------\n",
    "        pd.DataFrame\n",
    "            Dataframe con las nuevas caracteísticas calculadas\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"El dataset no ha sido cargado. Ejecute load_dataset() primero.\")\n",
    "        \n",
    "        self.data['ratio_deuda_ingresos'] = self.data['deuda_total_mxn']/self.data['ingresos_anuales_mxn']\n",
    "        self.data['carga_total_ingresos'] = (self.data['deuda_total_mxn'] + self.data['monto_solicitado_mxn'])/self.data['ingresos_anuales_mxn']\n",
    "        return self.data\n",
    "    \n",
    "    def select_features(self,list_features=[]):\n",
    "        \"\"\"\n",
    "        Selecciona las variables consideradas importantes para entrenar el modelo\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        list_features: list\n",
    "            Lista de nombres de columnas\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        pd.Dataframe\n",
    "            Dataframe compuesto solamente pos la columnas de la lista\n",
    "        \"\"\"\n",
    "        if len(list_features)>1:\n",
    "            self.data = self.data[list_features]\n",
    "        return self.data\n",
    "    \n",
    "    def encode_ordinal(self,name_col_ordinal ='calificacion_buro',dict_map ={}):\n",
    "        \"\"\"\n",
    "        Mapea una variable ordinal en base al diccionario ingresado\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        name_col_ordinal: str\n",
    "            Nombre de la columna ordinal a mapear\n",
    "            Por defecto es 'calificacion_buro'\n",
    "        dict_map: dict\n",
    "            Diccionario con las respectivar ordenes de mapeo.\n",
    "\n",
    "        Raise\n",
    "        -----\n",
    "        ValueError\n",
    "            Si el diccionario está vacio\n",
    "\n",
    "        Return\n",
    "        pd.DataFrame\n",
    "            Dataframe con la columna ordinal mapeada.\n",
    "        \"\"\"\n",
    "        if len(dict_map)>1:\n",
    "            self.data[name_col_ordinal] = self.data[name_col_ordinal].map(dict_map)\n",
    "        else:\n",
    "            raise ValueError(\"El diccionario de codificación ordinal está vacío.\")\n",
    "        return self.data\n",
    "    \n",
    "    def extract_sample(self, target='default_12m'):\n",
    "        \"\"\"\n",
    "        Extrae una muestra del DataFrame garantizando que las clases 0 y 1 \n",
    "        estén balanceadas, mediante estratificación en una columna de interés. \n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        target: str\n",
    "            Nombre de la columna que contiene las clases desbalanceadas\n",
    "            Por defecto es 'default_12m'\n",
    "\n",
    "        Raise\n",
    "        -----\n",
    "        KeyError\n",
    "            Si la columna ingresada no existe en el DataFrame\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        pd.DataFrame\n",
    "            Dataframe con las clases balanceadas\n",
    "        \"\"\"\n",
    "        if target in self.data.columns:\n",
    "            class_false = self.data[self.data[target]==0]\n",
    "            class_true = self.data[self.data[target]==1]\n",
    "\n",
    "            class_false_sub, _ = train_test_split(\n",
    "                class_false, # clase a submuestrear\n",
    "                train_size = len(class_true),\n",
    "                stratify = class_false['sector_industrial'], # estractifica por sector industrial\n",
    "                random_state = 43,\n",
    "                shuffle = True \n",
    "            )\n",
    "\n",
    "            data_sample = pd.concat([class_false_sub,class_true],axis=0)\n",
    "            self.data = data_sample.copy()\n",
    "        else:\n",
    "            raise KeyError(f\"La columna {target} no existe en el DataFrame.\")\n",
    "        return self.data\n",
    "    \n",
    "    def split_data(self,target='default_12m',test_size=0.05):\n",
    "        \"\"\"\n",
    "        Separa los datos en entrenamiento y  test\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        target: str\n",
    "            Nombre de la columna objetivo, por defecto es 'default_12m'.capitalize\n",
    "\n",
    "        test_size: float\n",
    "            Tamaño en porcentaje del dataset de prueba\n",
    "            por defecto es 5%\n",
    "        \n",
    "        Raise\n",
    "        -----\n",
    "        KeyError\n",
    "            Si la columna ingresada no existe en el dataframe\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        pd.DataFrame\n",
    "            DataFrames para entrenamiento y test\n",
    "        \"\"\"\n",
    "        if target in self.data.columns:\n",
    "\n",
    "            independientes = self.data.drop(columns=[target],axis=1)\n",
    "            objetivo = self.data[target]\n",
    "\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "            independientes,\n",
    "            objetivo,\n",
    "            test_size=test_size,\n",
    "            random_state=42,\n",
    "            shuffle=True,\n",
    "            stratify=self.data[target]\n",
    "            )\n",
    "\n",
    "            data_train = pd.concat([X_train,Y_train],axis=1)\n",
    "            data_test = pd.concat([X_test,Y_test],axis=1)\n",
    "\n",
    "            self.data_train = data_train.copy()\n",
    "            self.data_test = data_test.copy()\n",
    "        else:\n",
    "            raise KeyError(f\"La columna {target} no existe en el DataFrame.\")\n",
    "        return self.data_train, self.data_test \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a0e0c5",
   "metadata": {},
   "source": [
    "Veamos el funcionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ca5788",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data = MlDataPreprocessor(file_path('covalto_sme_credit_data_clean.csv'))\n",
    "data = prepare_data.load_dataset()\n",
    "\n",
    "data = prepare_data.create_features()\n",
    "data = prepare_data.encode_ordinal(\n",
    "    name_col_ordinal ='calificacion_buro',\n",
    "    dict_map={\n",
    "        np.nan:0,\n",
    "        'A':1,\n",
    "        'B':2,\n",
    "        'C':3,\n",
    "        'D':4\n",
    "    }\n",
    ")\n",
    "data = prepare_data.extract_sample(\n",
    "    target='default_12m'\n",
    ")\n",
    "\n",
    "data = prepare_data.select_features(list_features=[\n",
    "    'historial_pagos_atrasados',\n",
    "    'calificacion_buro',\n",
    "    'monto_solicitado_mxn',\n",
    "    'ratio_deuda_ingresos',\n",
    "    'carga_total_ingresos',\n",
    "    'default_12m'\n",
    "])\n",
    "\n",
    "data_train, data_test = prepare_data.split_data(\n",
    "    target='default_12m',\n",
    "    test_size=0.05\n",
    ")\n",
    "\n",
    "# Guardar los archivos \n",
    "dir_save_data = project_root/'data/processed'\n",
    "data_train.to_csv(dir_save_data/ 'covalto_sme_credit_train.csv', index=False)\n",
    "data_test.to_csv(dir_save_data/ 'covalto_sme_credit_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
